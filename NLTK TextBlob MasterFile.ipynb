{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXTBLOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Installing Text Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install testblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import textblob Librarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features of textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Noun phrase extraction - done\n",
    "\n",
    "2. Part-of-speech tagging - done\n",
    "\n",
    "3. Sentiment analysis - done\n",
    "\n",
    "4. Classification (Naive Bayes, Decision Tree) - done\n",
    "\n",
    "5. Language translation and detection powered by Google Translate - done\n",
    "\n",
    "6. Tokenization (splitting text into words and sentences) - done\n",
    "\n",
    "7. Word and phrase frequencies - done\n",
    "\n",
    "8. Parsing - done\n",
    "\n",
    "9. n-grams - done\n",
    "\n",
    "10. Word inflection (pluralization and singularization) and lemmatization - done\n",
    "\n",
    "11. Spelling correction - done\n",
    "\n",
    "12. word dictionary - done\n",
    "\n",
    "13. Add new models or languages through extensions\n",
    "\n",
    "14. WordNet integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Tokenization with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"\n",
       " Two long droughts ended on Saturday at the Copa America final: \n",
       " Argentina won its first major title since 1993 after a 1-0 win against Brazil.\"),\n",
       " Sentence(\"And Lionel Messi finally lifted his first major trophy for the national team, \n",
       " filling in one of the biggest gaps in his decorated career.\"),\n",
       " Sentence(\"Argentina’s winning goal at the Maracana Stadium in Rio de Janeiro came in the \n",
       " 22nd minute after Rodrigo de Paul made a long pass to Angel di Maria.\"),\n",
       " Sentence(\"The 33-year-old veteran striker counted on some sloppy defending from \n",
       " left-back Renan Lodi to take control and lob it past goalkeeper Ederson.\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "text = '''\n",
    "Two long droughts ended on Saturday at the Copa America final: \n",
    "Argentina won its first major title since 1993 after a 1-0 win against Brazil. \n",
    "And Lionel Messi finally lifted his first major trophy for the national team, \n",
    "filling in one of the biggest gaps in his decorated career.\n",
    "Argentina’s winning goal at the Maracana Stadium in Rio de Janeiro came in the \n",
    "22nd minute after Rodrigo de Paul made a long pass to Angel di Maria. \n",
    "The 33-year-old veteran striker counted on some sloppy defending from \n",
    "left-back Renan Lodi to take control and lob it past goalkeeper Ederson.\n",
    "'''\n",
    "blob_obj = TextBlob(text)\n",
    "# Divide into sentence\n",
    "blob_obj.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Two', 'long', 'droughts', 'ended', 'on', 'Saturday', 'at', 'the', 'Copa', 'America', 'final', 'Argentina', 'won', 'its', 'first', 'major', 'title', 'since', '1993', 'after', 'a', '1-0', 'win', 'against', 'Brazil', 'And', 'Lionel', 'Messi', 'finally', 'lifted', 'his', 'first', 'major', 'trophy', 'for', 'the', 'national', 'team', 'filling', 'in', 'one', 'of', 'the', 'biggest', 'gaps', 'in', 'his', 'decorated', 'career', 'Argentina', '’', 's', 'winning', 'goal', 'at', 'the', 'Maracana', 'Stadium', 'in', 'Rio', 'de', 'Janeiro', 'came', 'in', 'the', '22nd', 'minute', 'after', 'Rodrigo', 'de', 'Paul', 'made', 'a', 'long', 'pass', 'to', 'Angel', 'di', 'Maria', 'The', '33-year-old', 'veteran', 'striker', 'counted', 'on', 'some', 'sloppy', 'defending', 'from', 'left-back', 'Renan', 'Lodi', 'to', 'take', 'control', 'and', 'lob', 'it', 'past', 'goalkeeper', 'Ederson'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ḍivide into word\n",
    "blob_obj.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Two', 'long', 'droughts', 'ended', 'on', 'Saturday', 'at', 'the', 'Copa', 'America', 'final', ':', 'Argentina', 'won', 'its', 'first', 'major', 'title', 'since', '1993', 'after', 'a', '1-0', 'win', 'against', 'Brazil', '.', 'And', 'Lionel', 'Messi', 'finally', 'lifted', 'his', 'first', 'major', 'trophy', 'for', 'the', 'national', 'team', ',', 'filling', 'in', 'one', 'of', 'the', 'biggest', 'gaps', 'in', 'his', 'decorated', 'career', '.', 'Argentina', '’', 's', 'winning', 'goal', 'at', 'the', 'Maracana', 'Stadium', 'in', 'Rio', 'de', 'Janeiro', 'came', 'in', 'the', '22nd', 'minute', 'after', 'Rodrigo', 'de', 'Paul', 'made', 'a', 'long', 'pass', 'to', 'Angel', 'di', 'Maria', '.', 'The', '33-year-old', 'veteran', 'striker', 'counted', 'on', 'some', 'sloppy', 'defending', 'from', 'left-back', 'Renan', 'Lodi', 'to', 'take', 'control', 'and', 'lob', 'it', 'past', 'goalkeeper', 'Ederson', '.'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ḍivide into word\n",
    "blob_obj.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-POS tagging with TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob have two type of POS tagger\n",
    "    # PatternTagger (uses the same implementation as the pattern library)\n",
    "    # NLTKTagger which uses NLTK’s TreeBank tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Two', 'CD'),\n",
       " ('long', 'JJ'),\n",
       " ('droughts', 'NNS'),\n",
       " ('ended', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('Saturday', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Copa', 'NNP'),\n",
       " ('America', 'NNP'),\n",
       " ('final', 'JJ'),\n",
       " ('Argentina', 'NNP'),\n",
       " ('won', 'VBD'),\n",
       " ('its', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('major', 'JJ'),\n",
       " ('title', 'NN'),\n",
       " ('since', 'IN'),\n",
       " ('1993', 'CD'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('1-0', 'JJ'),\n",
       " ('win', 'NN'),\n",
       " ('against', 'IN'),\n",
       " ('Brazil', 'NNP'),\n",
       " ('And', 'CC'),\n",
       " ('Lionel', 'NNP'),\n",
       " ('Messi', 'NNP'),\n",
       " ('finally', 'RB'),\n",
       " ('lifted', 'VBD'),\n",
       " ('his', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('major', 'JJ'),\n",
       " ('trophy', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('national', 'JJ'),\n",
       " ('team', 'NN'),\n",
       " ('filling', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('biggest', 'JJS'),\n",
       " ('gaps', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('decorated', 'JJ'),\n",
       " ('career', 'NN'),\n",
       " ('Argentina', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('winning', 'VBG'),\n",
       " ('goal', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Maracana', 'NNP'),\n",
       " ('Stadium', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Rio', 'NNP'),\n",
       " ('de', 'IN'),\n",
       " ('Janeiro', 'NNP'),\n",
       " ('came', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('22nd', 'CD'),\n",
       " ('minute', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('Rodrigo', 'NNP'),\n",
       " ('de', 'FW'),\n",
       " ('Paul', 'NNP'),\n",
       " ('made', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('long', 'JJ'),\n",
       " ('pass', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('Angel', 'NNP'),\n",
       " ('di', 'FW'),\n",
       " ('Maria', 'NNP'),\n",
       " ('The', 'DT'),\n",
       " ('33-year-old', 'JJ'),\n",
       " ('veteran', 'NN'),\n",
       " ('striker', 'NN'),\n",
       " ('counted', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('sloppy', 'JJ'),\n",
       " ('defending', 'VBG'),\n",
       " ('from', 'IN'),\n",
       " ('left-back', 'JJ'),\n",
       " ('Renan', 'NNP'),\n",
       " ('Lodi', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('control', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('lob', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('past', 'JJ'),\n",
       " ('goalkeeper', 'JJ'),\n",
       " ('Ederson', 'NNP')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos_tag\n",
    "blob_obj.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Two', 'CD'),\n",
       " ('long', 'JJ'),\n",
       " ('droughts', 'NNS'),\n",
       " ('ended', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('Saturday', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Copa', 'NNP'),\n",
       " ('America', 'NNP'),\n",
       " ('final', 'JJ'),\n",
       " ('Argentina', 'NNP'),\n",
       " ('won', 'VBD'),\n",
       " ('its', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('major', 'JJ'),\n",
       " ('title', 'NN'),\n",
       " ('since', 'IN'),\n",
       " ('1993', 'CD'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('1-0', 'JJ'),\n",
       " ('win', 'NN'),\n",
       " ('against', 'IN'),\n",
       " ('Brazil', 'NNP'),\n",
       " ('And', 'CC'),\n",
       " ('Lionel', 'NNP'),\n",
       " ('Messi', 'NNP'),\n",
       " ('finally', 'RB'),\n",
       " ('lifted', 'VBD'),\n",
       " ('his', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('major', 'JJ'),\n",
       " ('trophy', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('national', 'JJ'),\n",
       " ('team', 'NN'),\n",
       " ('filling', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('biggest', 'JJS'),\n",
       " ('gaps', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('decorated', 'JJ'),\n",
       " ('career', 'NN'),\n",
       " ('Argentina', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('winning', 'VBG'),\n",
       " ('goal', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Maracana', 'NNP'),\n",
       " ('Stadium', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Rio', 'NNP'),\n",
       " ('de', 'IN'),\n",
       " ('Janeiro', 'NNP'),\n",
       " ('came', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('22nd', 'CD'),\n",
       " ('minute', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('Rodrigo', 'NNP'),\n",
       " ('de', 'FW'),\n",
       " ('Paul', 'NNP'),\n",
       " ('made', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('long', 'JJ'),\n",
       " ('pass', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('Angel', 'NNP'),\n",
       " ('di', 'FW'),\n",
       " ('Maria', 'NNP'),\n",
       " ('The', 'DT'),\n",
       " ('33-year-old', 'JJ'),\n",
       " ('veteran', 'NN'),\n",
       " ('striker', 'NN'),\n",
       " ('counted', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('sloppy', 'JJ'),\n",
       " ('defending', 'VBG'),\n",
       " ('from', 'IN'),\n",
       " ('left-back', 'JJ'),\n",
       " ('Renan', 'NNP'),\n",
       " ('Lodi', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('control', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('lob', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('past', 'JJ'),\n",
       " ('goalkeeper', 'JJ'),\n",
       " ('Ederson', 'NNP')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By using TreeBank tagger\n",
    "from textblob.taggers import NLTKTagger\n",
    "nltk_tagger = NLTKTagger()\n",
    "blob_obj = TextBlob(text, pos_tagger=nltk_tagger)\n",
    "blob_obj.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Two', 'CD'),\n",
       " ('long', 'JJ'),\n",
       " ('droughts', 'NNS'),\n",
       " ('ended', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('Saturday', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Copa', 'NNP'),\n",
       " ('America', 'NNP'),\n",
       " ('final', 'JJ'),\n",
       " ('Argentina', 'NNP'),\n",
       " ('won', 'VBD'),\n",
       " ('its', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('major', 'JJ'),\n",
       " ('title', 'NN'),\n",
       " ('since', 'IN'),\n",
       " ('1993', 'CD'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('1-0', 'CD'),\n",
       " ('win', 'VB'),\n",
       " ('against', 'IN'),\n",
       " ('Brazil', 'NNP'),\n",
       " ('And', 'CC'),\n",
       " ('Lionel', 'NNP'),\n",
       " ('Messi', 'NNP'),\n",
       " ('finally', 'RB'),\n",
       " ('lifted', 'VBD'),\n",
       " ('his', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('major', 'JJ'),\n",
       " ('trophy', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('national', 'JJ'),\n",
       " ('team', 'NN'),\n",
       " ('filling', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('biggest', 'JJS'),\n",
       " ('gaps', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('decorated', 'VBN'),\n",
       " ('career', 'NN'),\n",
       " ('Argentina', 'NNP'),\n",
       " ('’', 'NN'),\n",
       " ('s', 'PRP'),\n",
       " ('winning', 'VBG'),\n",
       " ('goal', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Maracana', 'NNP'),\n",
       " ('Stadium', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Rio', 'NNP'),\n",
       " ('de', 'FW'),\n",
       " ('Janeiro', 'NNP'),\n",
       " ('came', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('22nd', 'NN'),\n",
       " ('minute', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('Rodrigo', 'NNP'),\n",
       " ('de', 'FW'),\n",
       " ('Paul', 'NNP'),\n",
       " ('made', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('long', 'JJ'),\n",
       " ('pass', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('Angel', 'NNP'),\n",
       " ('di', 'NNP'),\n",
       " ('Maria', 'NNP'),\n",
       " ('The', 'DT'),\n",
       " ('33-year-old', 'JJ'),\n",
       " ('veteran', 'NN'),\n",
       " ('striker', 'NN'),\n",
       " ('counted', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('sloppy', 'JJ'),\n",
       " ('defending', 'VBG'),\n",
       " ('from', 'IN'),\n",
       " ('left-back', 'JJ'),\n",
       " ('Renan', 'NNP'),\n",
       " ('Lodi', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('control', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('lob', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('past', 'JJ'),\n",
       " ('goalkeeper', 'NN'),\n",
       " ('Ederson', 'NNP')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By using Pattern Tagger\n",
    "from textblob.taggers import PatternTagger\n",
    "pattern_tagger = PatternTagger()\n",
    "blob_obj = TextBlob(text, pos_tagger=pattern_tagger)\n",
    "blob_obj.pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Noun Phrase Extraction using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['long droughts',\n",
       " 'copa america',\n",
       " 'argentina',\n",
       " 'major title',\n",
       " 'brazil',\n",
       " 'lionel messi',\n",
       " 'major trophy',\n",
       " 'national team',\n",
       " 'argentina',\n",
       " '’ s',\n",
       " 'maracana',\n",
       " 'rio',\n",
       " 'janeiro',\n",
       " '22nd minute',\n",
       " 'rodrigo',\n",
       " 'paul',\n",
       " 'long pass',\n",
       " 'angel di',\n",
       " 'maria',\n",
       " '33-year-old veteran striker',\n",
       " 'renan lodi',\n",
       " 'past goalkeeper',\n",
       " 'ederson']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(blob_obj.noun_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Word Inflection and Lemmatization using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prvious:  its  After:  it\n",
      "Prvious:  the  After:  thes\n"
     ]
    }
   ],
   "source": [
    "# Singularize form\n",
    "print('Prvious: ', blob_obj.words[13], ' After: ', blob_obj.words[13].singularize())\n",
    "# Pluralize form\n",
    "print('Prvious: ', blob_obj.words[7], ' After: ', blob_obj.words[7].pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "\n",
    "from textblob import Word\n",
    "\n",
    "q = Word('history')\n",
    "q.stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization\n",
    "\n",
    "q = Word('history')\n",
    "q.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization with base verbe\n",
    "\n",
    "q = Word('went')\n",
    "q.lemmatize('v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-N-grams using TextBlob\n",
    "#### N-Gram is combination of multiple words together. N grams can be used as features for language modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Two', 'long', 'droughts']),\n",
       " WordList(['long', 'droughts', 'ended']),\n",
       " WordList(['droughts', 'ended', 'on']),\n",
       " WordList(['ended', 'on', 'Saturday']),\n",
       " WordList(['on', 'Saturday', 'at']),\n",
       " WordList(['Saturday', 'at', 'the']),\n",
       " WordList(['at', 'the', 'Copa']),\n",
       " WordList(['the', 'Copa', 'America']),\n",
       " WordList(['Copa', 'America', 'final']),\n",
       " WordList(['America', 'final', 'Argentina']),\n",
       " WordList(['final', 'Argentina', 'won']),\n",
       " WordList(['Argentina', 'won', 'its']),\n",
       " WordList(['won', 'its', 'first']),\n",
       " WordList(['its', 'first', 'major']),\n",
       " WordList(['first', 'major', 'title']),\n",
       " WordList(['major', 'title', 'since']),\n",
       " WordList(['title', 'since', '1993']),\n",
       " WordList(['since', '1993', 'after']),\n",
       " WordList(['1993', 'after', 'a']),\n",
       " WordList(['after', 'a', '1-0']),\n",
       " WordList(['a', '1-0', 'win']),\n",
       " WordList(['1-0', 'win', 'against']),\n",
       " WordList(['win', 'against', 'Brazil']),\n",
       " WordList(['against', 'Brazil', 'And']),\n",
       " WordList(['Brazil', 'And', 'Lionel']),\n",
       " WordList(['And', 'Lionel', 'Messi']),\n",
       " WordList(['Lionel', 'Messi', 'finally']),\n",
       " WordList(['Messi', 'finally', 'lifted']),\n",
       " WordList(['finally', 'lifted', 'his']),\n",
       " WordList(['lifted', 'his', 'first']),\n",
       " WordList(['his', 'first', 'major']),\n",
       " WordList(['first', 'major', 'trophy']),\n",
       " WordList(['major', 'trophy', 'for']),\n",
       " WordList(['trophy', 'for', 'the']),\n",
       " WordList(['for', 'the', 'national']),\n",
       " WordList(['the', 'national', 'team']),\n",
       " WordList(['national', 'team', 'filling']),\n",
       " WordList(['team', 'filling', 'in']),\n",
       " WordList(['filling', 'in', 'one']),\n",
       " WordList(['in', 'one', 'of']),\n",
       " WordList(['one', 'of', 'the']),\n",
       " WordList(['of', 'the', 'biggest']),\n",
       " WordList(['the', 'biggest', 'gaps']),\n",
       " WordList(['biggest', 'gaps', 'in']),\n",
       " WordList(['gaps', 'in', 'his']),\n",
       " WordList(['in', 'his', 'decorated']),\n",
       " WordList(['his', 'decorated', 'career']),\n",
       " WordList(['decorated', 'career', 'Argentina']),\n",
       " WordList(['career', 'Argentina', '’']),\n",
       " WordList(['Argentina', '’', 's']),\n",
       " WordList(['’', 's', 'winning']),\n",
       " WordList(['s', 'winning', 'goal']),\n",
       " WordList(['winning', 'goal', 'at']),\n",
       " WordList(['goal', 'at', 'the']),\n",
       " WordList(['at', 'the', 'Maracana']),\n",
       " WordList(['the', 'Maracana', 'Stadium']),\n",
       " WordList(['Maracana', 'Stadium', 'in']),\n",
       " WordList(['Stadium', 'in', 'Rio']),\n",
       " WordList(['in', 'Rio', 'de']),\n",
       " WordList(['Rio', 'de', 'Janeiro']),\n",
       " WordList(['de', 'Janeiro', 'came']),\n",
       " WordList(['Janeiro', 'came', 'in']),\n",
       " WordList(['came', 'in', 'the']),\n",
       " WordList(['in', 'the', '22nd']),\n",
       " WordList(['the', '22nd', 'minute']),\n",
       " WordList(['22nd', 'minute', 'after']),\n",
       " WordList(['minute', 'after', 'Rodrigo']),\n",
       " WordList(['after', 'Rodrigo', 'de']),\n",
       " WordList(['Rodrigo', 'de', 'Paul']),\n",
       " WordList(['de', 'Paul', 'made']),\n",
       " WordList(['Paul', 'made', 'a']),\n",
       " WordList(['made', 'a', 'long']),\n",
       " WordList(['a', 'long', 'pass']),\n",
       " WordList(['long', 'pass', 'to']),\n",
       " WordList(['pass', 'to', 'Angel']),\n",
       " WordList(['to', 'Angel', 'di']),\n",
       " WordList(['Angel', 'di', 'Maria']),\n",
       " WordList(['di', 'Maria', 'The']),\n",
       " WordList(['Maria', 'The', '33-year-old']),\n",
       " WordList(['The', '33-year-old', 'veteran']),\n",
       " WordList(['33-year-old', 'veteran', 'striker']),\n",
       " WordList(['veteran', 'striker', 'counted']),\n",
       " WordList(['striker', 'counted', 'on']),\n",
       " WordList(['counted', 'on', 'some']),\n",
       " WordList(['on', 'some', 'sloppy']),\n",
       " WordList(['some', 'sloppy', 'defending']),\n",
       " WordList(['sloppy', 'defending', 'from']),\n",
       " WordList(['defending', 'from', 'left-back']),\n",
       " WordList(['from', 'left-back', 'Renan']),\n",
       " WordList(['left-back', 'Renan', 'Lodi']),\n",
       " WordList(['Renan', 'Lodi', 'to']),\n",
       " WordList(['Lodi', 'to', 'take']),\n",
       " WordList(['to', 'take', 'control']),\n",
       " WordList(['take', 'control', 'and']),\n",
       " WordList(['control', 'and', 'lob']),\n",
       " WordList(['and', 'lob', 'it']),\n",
       " WordList(['lob', 'it', 'past']),\n",
       " WordList(['it', 'past', 'goalkeeper']),\n",
       " WordList(['past', 'goalkeeper', 'Ederson'])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_obj.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Two']),\n",
       " WordList(['long']),\n",
       " WordList(['droughts']),\n",
       " WordList(['ended']),\n",
       " WordList(['on']),\n",
       " WordList(['Saturday']),\n",
       " WordList(['at']),\n",
       " WordList(['the']),\n",
       " WordList(['Copa']),\n",
       " WordList(['America']),\n",
       " WordList(['final']),\n",
       " WordList(['Argentina']),\n",
       " WordList(['won']),\n",
       " WordList(['its']),\n",
       " WordList(['first']),\n",
       " WordList(['major']),\n",
       " WordList(['title']),\n",
       " WordList(['since']),\n",
       " WordList(['1993']),\n",
       " WordList(['after']),\n",
       " WordList(['a']),\n",
       " WordList(['1-0']),\n",
       " WordList(['win']),\n",
       " WordList(['against']),\n",
       " WordList(['Brazil']),\n",
       " WordList(['And']),\n",
       " WordList(['Lionel']),\n",
       " WordList(['Messi']),\n",
       " WordList(['finally']),\n",
       " WordList(['lifted']),\n",
       " WordList(['his']),\n",
       " WordList(['first']),\n",
       " WordList(['major']),\n",
       " WordList(['trophy']),\n",
       " WordList(['for']),\n",
       " WordList(['the']),\n",
       " WordList(['national']),\n",
       " WordList(['team']),\n",
       " WordList(['filling']),\n",
       " WordList(['in']),\n",
       " WordList(['one']),\n",
       " WordList(['of']),\n",
       " WordList(['the']),\n",
       " WordList(['biggest']),\n",
       " WordList(['gaps']),\n",
       " WordList(['in']),\n",
       " WordList(['his']),\n",
       " WordList(['decorated']),\n",
       " WordList(['career']),\n",
       " WordList(['Argentina']),\n",
       " WordList(['’']),\n",
       " WordList(['s']),\n",
       " WordList(['winning']),\n",
       " WordList(['goal']),\n",
       " WordList(['at']),\n",
       " WordList(['the']),\n",
       " WordList(['Maracana']),\n",
       " WordList(['Stadium']),\n",
       " WordList(['in']),\n",
       " WordList(['Rio']),\n",
       " WordList(['de']),\n",
       " WordList(['Janeiro']),\n",
       " WordList(['came']),\n",
       " WordList(['in']),\n",
       " WordList(['the']),\n",
       " WordList(['22nd']),\n",
       " WordList(['minute']),\n",
       " WordList(['after']),\n",
       " WordList(['Rodrigo']),\n",
       " WordList(['de']),\n",
       " WordList(['Paul']),\n",
       " WordList(['made']),\n",
       " WordList(['a']),\n",
       " WordList(['long']),\n",
       " WordList(['pass']),\n",
       " WordList(['to']),\n",
       " WordList(['Angel']),\n",
       " WordList(['di']),\n",
       " WordList(['Maria']),\n",
       " WordList(['The']),\n",
       " WordList(['33-year-old']),\n",
       " WordList(['veteran']),\n",
       " WordList(['striker']),\n",
       " WordList(['counted']),\n",
       " WordList(['on']),\n",
       " WordList(['some']),\n",
       " WordList(['sloppy']),\n",
       " WordList(['defending']),\n",
       " WordList(['from']),\n",
       " WordList(['left-back']),\n",
       " WordList(['Renan']),\n",
       " WordList(['Lodi']),\n",
       " WordList(['to']),\n",
       " WordList(['take']),\n",
       " WordList(['control']),\n",
       " WordList(['and']),\n",
       " WordList(['lob']),\n",
       " WordList(['it']),\n",
       " WordList(['past']),\n",
       " WordList(['goalkeeper']),\n",
       " WordList(['Ederson'])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_obj.ngrams(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-Sentiment Analysis using TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis is the process of determining the emotion (positive or negative or neutral) of a text.\n",
    "The sentiment function of TextBlob has two properties, which are:\n",
    "\n",
    "-Polarity (range -1 to 1) \n",
    "\n",
    "-Subjectivity (range 0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.8, subjectivity=0.9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I hate this phone\"\n",
    "blob_obj = TextBlob(text)\n",
    "blob_obj.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5, subjectivity=0.6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love this phone\"\n",
    "blob_obj = TextBlob(text)\n",
    "blob_obj.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER sentiment\n",
    "Valence aware dictionary for sentiment reasoning (VADER) is another popular rule-based sentiment analyzer. \n",
    "\n",
    "It uses a list of lexical features (e.g. word) which are labeled as positive or negative according to their semantic orientation to calculate the text sentiment.   \n",
    "\n",
    "Vader sentiment returns the probability of a given input sentence to be \n",
    "\n",
    "Positive, negative, and neutral. \n",
    "\n",
    "For example:\n",
    "\n",
    "“The food was great!”\n",
    "Positive : 99%\n",
    "Negative :1%\n",
    "Neutral : 0%\n",
    "\n",
    "These three probabilities will add up to 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentence = \"The food was great!\" \n",
    "vs = analyzer.polarity_scores(sentence)\n",
    "print(\"{:-<65} {}\".format(sentence, str(vs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flair \n",
    "Flair is a simple to use framework for state of the art NLP. \n",
    "\n",
    "It provided various functionalities such as:\n",
    "\n",
    "pre-trained sentiment analysis models, \n",
    "text embeddings, \n",
    "NER, \n",
    "and more.\n",
    "Let’s see how to very easily and efficiently do sentiment analysis using flair.\n",
    "\n",
    "Flair pretrained sentiment analysis model is trained on IMDB dataset. To load and make prediction using it simply do:\n",
    "\n",
    "\n",
    "[POSITIVE (0.9961)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "sentence = Sentence('The food was great!')\n",
    "classifier.predict(sentence)\n",
    "\n",
    "# print sentence with predicted labels\n",
    "print('Sentence above is: ', sentence.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like to have a custom sentiment analyzer for your domain, \n",
    "it is possible to train a classifier using flair using your dataset.\n",
    "\n",
    "The drawback of using a flair pre-trained model for sentiment analysis is that it is trained on \n",
    "IMDB data and this model might not generalize well on data from other domains like twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-Spelling Correction using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-498a084a6f01>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-498a084a6f01>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    In nlp sometimes spelling correction is mostly required to normalize text data. TextBlob offers spelling corrector with 80-90% accuracy at a processing speed of at least 10 words per second.\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "In nlp sometimes spelling correction is mostly required to normalize text data. TextBlob offers spelling corrector with 80-90% accuracy at a processing speed of at least 10 words per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-e04fdad235e8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-e04fdad235e8>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Spelling corrector is Based on: Peter Norvig, “How to Write a Spelling Corrector”\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Spelling corrector is Based on: Peter Norvig, “How to Write a Spelling Corrector”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spelling', 1.0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_obj = TextBlob(\"speling\")\n",
    "blob_obj.words[0].spellcheck()\n",
    "[('spelling', 1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An you pronounce czechoslovakia?\n"
     ]
    }
   ],
   "source": [
    "g = TextBlob('Can yoeu pronounce czechuslovakia?')\n",
    "print(g.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('An', 0.5222764723832773),\n",
       " ('Man', 0.25205981080256334),\n",
       " ('Can', 0.1670735428745804),\n",
       " ('Ran', 0.049130302105584375),\n",
       " ('San', 0.003051571559353067),\n",
       " ('Van', 0.0028989929813854134),\n",
       " ('Fan', 0.0012206286237412267),\n",
       " ('Ban', 0.00091547146780592),\n",
       " ('Pan', 0.0006103143118706134),\n",
       " ('Dan', 0.0003051571559353067),\n",
       " ('Wan', 0.00015257857796765334),\n",
       " ('Nan', 0.00015257857796765334),\n",
       " ('Jan', 0.00015257857796765334)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spell check\n",
    "\n",
    "k = Word('Can')\n",
    "k.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-Language detection and Translation using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Detect Language\n",
    "text = \"I hate this phone\"\n",
    "blob_obj = TextBlob(text)\n",
    "blob_obj.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Detect Language with proxy\n",
    "from textblob import TextBlob\n",
    "# Set up your proxy address\n",
    "# nltk.set_proxy('http://111.199.236.103:8080') \n",
    "text = \"I hate this phone\"\n",
    "blob_obj = TextBlob(text)\n",
    "blob_obj.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मला हे रेस्टॉरंट आवडत नाही\n",
      "मुझे यह रेस्टोरेंट पसंद नहीं है\n",
      "મને આ રેસ્ટોરન્ટ પસંદ નથી\n",
      "ఈ రెస్టారెంట్ నాకు నచ్చలేదు\n",
      "இந்த உணவகம் எனக்கு பிடிக்கவில்லை\n",
      "আমি এই রেস্তোঁরা পছন্দ করি না\n",
      "مجھے یہ ریستوراں پسند نہیں ہے\n",
      "ମୁଁ ଏହି ରେଷ୍ଟୁରାଣ୍ଟକୁ ପସନ୍ଦ କରେ ନାହିଁ |\n",
      "ਮੈਨੂੰ ਇਹ ਰੈਸਟੋਰੈਂਟ ਪਸੰਦ ਨਹੀਂ\n"
     ]
    },
    {
     "ename": "NotTranslated",
     "evalue": "Translation API returned the input string unchanged.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotTranslated\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-8f88f3ca4396>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'or'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'pa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, from_lang, to)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \"\"\"\n\u001b[0;32m    546\u001b[0m         return self.__class__(self.translator.translate(self.raw,\n\u001b[1;32m--> 547\u001b[1;33m                               from_lang=from_lang, to_lang=to))\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdetect_language\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\textblob\\translate.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, source, from_lang, to_lang, host, type_)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_translation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\textblob\\translate.py\u001b[0m in \u001b[0;36m_validate_translation\u001b[1;34m(self, source, result)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNotTranslated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Translation API returned the input string unchanged.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotTranslated\u001b[0m: Translation API returned the input string unchanged."
     ]
    }
   ],
   "source": [
    "## Translate to hindi language\n",
    "blob_obj = TextBlob(\"I do not like this restaurant\")\n",
    "print(blob_obj.translate(to = 'mr'))\n",
    "print(blob_obj.translate(to = 'hi'))\n",
    "print(blob_obj.translate(to = 'gu'))\n",
    "print(blob_obj.translate(to = 'te'))\n",
    "print(blob_obj.translate(to = 'ta'))\n",
    "print(blob_obj.translate(to = 'bn'))\n",
    "print(blob_obj.translate(to = 'ur'))\n",
    "print(blob_obj.translate(to = 'or'))\n",
    "print(blob_obj.translate(to = 'pa'))\n",
    "print(blob_obj.translate(to = 'en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = TextBlob('She sales Sea shells at the sea shore')\n",
    "sent.word_counts['sea']\n",
    "\n",
    "#  or\n",
    "\n",
    "sent.words.count('sea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-Defination Usind TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"any of various games played with a ball (round or oval) in which two teams try to kick or carry or propel the ball into each other's goal\",\n",
       " 'the inflated oblong ball used in playing American football']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('football').definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
